{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train[:10000].reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test[:2000].reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train[:10000])\n",
        "y_test = to_categorical(y_test[:2000])\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')])\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    validation_split=0.1,\n",
        "    verbose=1,\n",
        "    batch_size=128  )\n",
        "def generate_adversarial_examples(x, y, model, epsilon=0.1):\n",
        "    adv_examples = []\n",
        "    for i in range(len(x)):\n",
        "        sample = tf.convert_to_tensor(x[i:i+1], dtype=tf.float32)\n",
        "        label = tf.convert_to_tensor(y[i:i+1], dtype=tf.float32)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(sample)\n",
        "            predictions = model(sample)\n",
        "            loss = tf.keras.losses.categorical_crossentropy(label, predictions)\n",
        "        gradients = tape.gradient(loss, sample)\n",
        "        signed_grad = tf.sign(gradients)\n",
        "        perturbed_x = sample + epsilon * signed_grad\n",
        "        perturbed_x = tf.clip_by_value(perturbed_x, 0, 1)\n",
        "        adv_examples.append(perturbed_x.numpy())\n",
        "    adv_examples = np.array(adv_examples)\n",
        "    adv_examples = np.squeeze(adv_examples, axis=1)\n",
        "    print(f\"Shape of adversarial examples: {adv_examples.shape}\")\n",
        "    return adv_examples\n",
        "\n",
        "x_adv = generate_adversarial_examples(x_test, y_test, model, epsilon=0.1)\n",
        "assert x_adv.shape == (x_test.shape[0], 28, 28, 1), f\"Shape mismatch: {x_adv.shape}\"\n",
        "adv_loss, adv_acc = model.evaluate(x_adv, y_test)\n",
        "print(f\"\\nAdversarial Test Accuracy: {adv_acc:.4f}\")\n",
        "def tangent_distance(x1, x2):\n",
        "    x1_flat = x1.flatten()\n",
        "    x2_flat = x2.flatten()\n",
        "    return np.linalg.norm(x1_flat - x2_flat)\n",
        "sample_dist = tangent_distance(x_test[0], x_test[1])\n",
        "print(f\"\\nTangent Distance between samples: {sample_dist:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ0W5ML2S39E",
        "outputId": "593f943d-d296-4476-ddcd-765c57e62e70"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5292 - loss: 1.5628 - val_accuracy: 0.8960 - val_loss: 0.3797\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.8931 - loss: 0.3734 - val_accuracy: 0.9170 - val_loss: 0.2765\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.9195 - loss: 0.2793 - val_accuracy: 0.9230 - val_loss: 0.2401\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9322 - loss: 0.2334 - val_accuracy: 0.9290 - val_loss: 0.2157\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9414 - loss: 0.1995 - val_accuracy: 0.9360 - val_loss: 0.1961\n",
            "Shape of adversarial examples: (2000, 28, 28, 1)\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3690 - loss: 2.1864\n",
            "\n",
            "Adversarial Test Accuracy: 0.3525\n",
            "\n",
            "Tangent Distance between samples: 11.2688\n"
          ]
        }
      ]
    }
  ]
}